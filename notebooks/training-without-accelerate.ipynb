{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1207c5aaa5df4118a1af00d50d2e6b67":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17cfae26cf3f427a9293f8e9d91e3592":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7068f9b8fa7841f8be47e3d72bb3e049","placeholder":"​","style":"IPY_MODEL_e3b73dce015c4c64b499fff0c80e2bbd","value":" 2/2 [00:00&lt;00:00, 58.12it/s]"}},"2c76773648af4ae5aa6ff86c85ffe494":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d417fe59ae748cb9305f1fab5cac0b1","IPY_MODEL_39e32c6502914f93962b211f7e3c0717","IPY_MODEL_17cfae26cf3f427a9293f8e9d91e3592"],"layout":"IPY_MODEL_9c6161f025594acab91dd6361ce18ce5"}},"39e32c6502914f93962b211f7e3c0717":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b42f245e22947bdb39587c4600e65a7","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8c1b65b6bae4ee3a18e302a21a26d9f","value":2}},"4b42f245e22947bdb39587c4600e65a7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b74ee5b1cd9472593a310c92f2ab49f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7248b810b4a8482c9afb7fb93c7a533a","placeholder":"​","style":"IPY_MODEL_c1dd4d56605542f0af93a40f82ccf714","value":"100%"}},"5d450c2dfae44fdaa8229b9b9f7f3198":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7068f9b8fa7841f8be47e3d72bb3e049":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7248b810b4a8482c9afb7fb93c7a533a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d417fe59ae748cb9305f1fab5cac0b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b80d836ec5af4b99a4235ef8a2eea34b","placeholder":"​","style":"IPY_MODEL_8a0cfde997dc4f3cb0cc9d9a271a9855","value":"100%"}},"8a0cfde997dc4f3cb0cc9d9a271a9855":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97c155881fbd441494b6840a2e6563f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d450c2dfae44fdaa8229b9b9f7f3198","placeholder":"​","style":"IPY_MODEL_ac6c4fba09264a0ea281021484a62bd8","value":" 2/2 [00:00&lt;00:00, 50.24it/s]"}},"9c6161f025594acab91dd6361ce18ce5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a32e40fc891c4c6980bab9d56f940e70":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac6c4fba09264a0ea281021484a62bd8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7cfe59369324991be4e9daff711bad5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b74ee5b1cd9472593a310c92f2ab49f","IPY_MODEL_bc4ddc9f5b734dd9be52a905461fb2b4","IPY_MODEL_97c155881fbd441494b6840a2e6563f6"],"layout":"IPY_MODEL_a32e40fc891c4c6980bab9d56f940e70"}},"b80d836ec5af4b99a4235ef8a2eea34b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8c1b65b6bae4ee3a18e302a21a26d9f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bc4ddc9f5b734dd9be52a905461fb2b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1207c5aaa5df4118a1af00d50d2e6b67","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ccd3cb0072d2425f996c5da1ebfe3d3a","value":2}},"c1dd4d56605542f0af93a40f82ccf714":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ccd3cb0072d2425f996c5da1ebfe3d3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e3b73dce015c4c64b499fff0c80e2bbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Large Language Models in limited hardware environments - training template","metadata":{}},{"cell_type":"code","source":"!pip install torch==1.13.0 transformers==4.28.1 datasets==2.1.0 evaluate==0.4.0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m_feUQEoXDLa","outputId":"146af9f8-cd7a-4462-88bd-ca0f63874e9f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import evaluate\nimport torch\nfrom datasets import load_dataset\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, get_linear_schedule_with_warmup, set_seed\n\nfrom tqdm import tqdm\n\nfrom typing import Dict","metadata":{"id":"dd2y_MfmXneH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataloaders(model_id: str, batch_size: int):\n    tokenizer = AutoTokenizer.from_pretrained(model_id)\n    datasets = load_dataset(\"banking77\")\n\n    def tokenize_function(examples):\n        outputs = tokenizer(examples[\"text\"], truncation=True, max_length=None)\n        return outputs\n    \n    tokenized_datasets = datasets.map(\n            tokenize_function,\n            batched=True,\n            remove_columns=[\"text\"],\n        )\n    \n    tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n\n    def collate_fn(examples):\n        pad_to_multiple_of = None\n        max_length = None\n\n        return tokenizer.pad(\n            examples,\n            padding=\"longest\",\n            max_length=max_length,\n            pad_to_multiple_of=pad_to_multiple_of,\n            return_tensors=\"pt\",\n        )\n\n    train_dataloader = DataLoader(\n        tokenized_datasets[\"train\"], \n        shuffle=True, \n        collate_fn=collate_fn, \n        batch_size=batch_size, \n        drop_last=True\n    )\n    eval_dataloader = DataLoader(\n        tokenized_datasets[\"test\"],\n        shuffle=False,\n        collate_fn=collate_fn,\n        batch_size=batch_size\n    )\n\n    return train_dataloader, eval_dataloader","metadata":{"id":"hsv2OpmTXlme","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(train_args: Dict, model_id: str, mixed_precision: str=\"no\", ds_config: str=None):        \n    train_dataloader, eval_dataloader = get_dataloaders(model_id, train_args[\"batch_size\"])\n    \n    model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=77)\n    device = torch.device(\"cuda\")\n    model = model.to(device)\n\n    optimizer = AdamW(params=model.parameters(), lr=train_args[\"lr\"])\n    gradient_accumulation_steps = train_args[\"gradient_accumulation_steps\"]\n    \n    lr_scheduler = get_linear_schedule_with_warmup(\n        optimizer=optimizer,\n        num_warmup_steps=train_args[\"num_warmup_steps\"],\n        num_training_steps=(len(train_dataloader) * train_args[\"num_epochs\"]) // gradient_accumulation_steps,\n    )\n          \n    metric = evaluate.load(train_args[\"metric\"])\n\n    for epoch in range(train_args[\"num_epochs\"]):\n        model.train()\n        pbar = tqdm(train_dataloader)\n        \n        for step, batch in enumerate(pbar):\n            batch.to(device)\n            outputs = model(**batch)\n            loss = outputs.loss\n            loss = loss / gradient_accumulation_steps\n            \n            loss.backward()\n            if step % gradient_accumulation_steps == 0:\n                optimizer.step()\n                lr_scheduler.step()\n                optimizer.zero_grad()\n                \n            pbar.set_description(f\"epoch {epoch} iter {step}: train loss {loss.item():.5f}.\")\n\n        model.eval()\n        for step, batch in enumerate(eval_dataloader):\n            batch.to(device)\n            with torch.no_grad():\n                outputs = model(**batch)\n            predictions = outputs.logits.argmax(dim=-1)\n            references = batch[\"labels\"]\n            metric.add_batch(\n                predictions=predictions,\n                references=references,\n            )\n\n        eval_metric = metric.compute()\n        \n        print(f\"epoch {epoch}:\", eval_metric)\n    model.save(\"model.pkl\")","metadata":{"id":"kOiryCj-atUU","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_ID = \"bert-large-cased\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_params = {\n    \"lr\": 2e-5, \n    \"num_epochs\": 5, \n    \"batch_size\": 8, \n    \"metric\": \"accuracy\", \n    \"gradient_accumulation_steps\": 4, \n    \"num_warmup_steps\": 100\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(train_params, MODEL_ID)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}